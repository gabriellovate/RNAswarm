{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions for analysis of SPLASH np.arrays\n",
    "import io_ops as iops\n",
    "import find_interactions as fi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and viral features:\n",
    "DIRECTORY = \"/home/ru27wav/Projects/gl_iav-splash_freiburg\"\n",
    "INPUT = f\"{DIRECTORY}/data/arrays_IAV_wt_vs_mut\"\n",
    "RESULT = f\"{DIRECTORY}/results/test\"\n",
    "iav_segments = [\"PB2\", \"PB1\", \"PA\", \"HA\", \"NP\", \"NA\", \"M\", \"NS\"]\n",
    "strains = [\"wt\", \"mut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8673/3535239130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read the arrays from file and put them into dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m wt_d_repDir2Combinations, wt_d_combinations2arrays = iops.read_arrays(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34mf'{INPUT}/wt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miav_segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dessertlocal/projects/gl_iav-splash_freiburg/src/slosh/io_ops.py\u001b[0m in \u001b[0;36mread_arrays\u001b[0;34m(data_directory, viral_segments)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallCombinations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0muniqueID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{segments_to_regex.search(combination).group()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_directory}/{repDir}/{combination}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muniqueID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_combination2Array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# Read the arrays from file and put them into dictionaries\n",
    "wt_d_repDir2Combinations, wt_d_combinations2arrays = iops.read_arrays(\n",
    "    f'{INPUT}/wt', iav_segments\n",
    ")\n",
    "\n",
    "mut_d_repDir2Combinations, mut_d_combinations2arrays = iops.read_arrays(\n",
    "    f'{INPUT}/mut', iav_segments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the arrays and filter the regions with readcounts greater than the mean of all values...\n",
    "wt_d_combinations2arrays_filtered = {}\n",
    "for combination, arrays in wt_d_combinations2arrays.items():\n",
    "    for i in range(len(arrays)):\n",
    "        if i == 0:\n",
    "            wt_d_combinations2arrays_filtered[combination] = [fi.mean_filter(arrays[i])]\n",
    "        else:\n",
    "            wt_d_combinations2arrays_filtered[combination].append(\n",
    "                fi.mean_filter(arrays[i])\n",
    "            )\n",
    "\n",
    "mut_d_combinations2arrays_filtered = {}\n",
    "for combination, arrays in mut_d_combinations2arrays.items():\n",
    "    for i in range(len(arrays)):\n",
    "        if i == 0:\n",
    "            mut_d_combinations2arrays_filtered[combination] = [fi.mean_filter(arrays[i])]\n",
    "        else:\n",
    "            mut_d_combinations2arrays_filtered[combination].append(\n",
    "                fi.mean_filter(arrays[i])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the binary arrays\n",
    "# This is kind of a hack (ugly hack), it doesn't generalize very well\n",
    "\n",
    "d_combinations2arrays_combined = {}\n",
    "for combination, arrays in wt_d_combinations2arrays_filtered.items():\n",
    "    arrays.append(mut_d_combinations2arrays_filtered[combination][0])\n",
    "    d_combinations2arrays_combined[combination] = fi.combine_filters(arrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of coordinates\n",
    "d_combinations2coordinates = {}\n",
    "for combination, array in d_combinations2arrays_combined.items():\n",
    "    d_combinations2coordinates[combination] = fi.extract_coordinates(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of regions\n",
    "d_combinations2regions = {}\n",
    "for combination, coordinates in d_combinations2coordinates.items():\n",
    "    d_combinations2regions[combination] = fi.extract_regions(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the mean countvalue for each region\n",
    "wt_d_combinations2means = {}\n",
    "for combination, regions in d_combinations2regions.items():\n",
    "    wt_d_combinations2means[combination] = [\n",
    "        fi.readcounts_to_means(regions, array)\n",
    "        for array in wt_d_combinations2arrays[combination]\n",
    "    ]\n",
    "\n",
    "mut_d_combinations2means = {}\n",
    "for combination, regions in d_combinations2regions.items():\n",
    "    mut_d_combinations2means[combination] = [\n",
    "        fi.readcounts_to_means(regions, array)\n",
    "        for array in mut_d_combinations2arrays[combination]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format each of the mean dictionaries to a .csv file and save it\n",
    "for combination, means in wt_d_combinations2means.items():\n",
    "    iops.format_means_to_table(\n",
    "        wt_d_combinations2means[combination],\n",
    "        output_path=f\"{RESULT}/wt_{combination}_interactions.csv\",\n",
    "    )\n",
    "\n",
    "for combination, means in mut_d_combinations2means.items():\n",
    "    iops.format_means_to_table(\n",
    "        mut_d_combinations2means[combination],\n",
    "        output_path=f\"{RESULT}/mut_{combination}_interactions.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slosh_dataset = {}\n",
    "for combination in d_combinations2arrays_combined.keys():\n",
    "        # This loop goest through the same combinations lots of times, (ugly hack) this has to be fixed\n",
    "            slosh_dataset[f\"{combination}\"] = {\n",
    "                strain : pd.read_csv(f\"{RESULT}/{strain}_{combination}_interactions.csv\", index_col=0, header=None,) for strain in strains\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column name of dataframes\n",
    "for combination, strain2df in slosh_dataset.items():\n",
    "    for strain, df in strain2df.items():\n",
    "        slosh_dataset[combination][strain].columns = [strain for i in range(len(slosh_dataset[combination][strain].columns))]\n",
    "\n",
    "# Consolidate dataframes\n",
    "slosh_dataset_consolidated = {}\n",
    "for combination, strain2df in slosh_dataset.items():\n",
    "    slosh_dataset_consolidated[combination] = pd.concat([df for df in strain2df.values()], axis=1)\n",
    "\n",
    "# Rename interaction ids\n",
    "for combination, df in slosh_dataset_consolidated.items():\n",
    "    for id in df.index:\n",
    "        df = df.rename(index={id: f\"{combination}-{id}\"})\n",
    "    slosh_dataset_consolidated[combination] = df\n",
    "\n",
    "slosh_df = pd.concat(slosh_dataset_consolidated.values(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with fake data (ugly hack)\n",
    "slosh_df = pd.concat([slosh_df, slosh_df[\"mut\"], slosh_df[\"mut\"]], axis=1)\n",
    "slosh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slosh_df.to_csv(f\"{RESULT}/wt_mut_interactions.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c651144440c1aeec3027a9600178a13e028b6a36664423ef2ed70684e4fc7e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('iav_splash-dev': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
